#here first we will find the number of pages from the base page(soup)
#then we wii form final url of every page
#then we will open  each page annd scrap content .


import requests
from bs4 import BeautifulSoup
import pandas

#finding last page number
r=requests.get("https://www.flipkart.com/search?q=samsung%20best%20mobiles&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off",headers={'User-agent':'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:61.0) Gecko/20100101 Firefox/61.0'}) #this is base base  (not page 1)
c=r.content
soup=BeautifulSoup(c,"html.parser")
last_page=soup.find_all("a",{"class":"ge-49M"})[-1].text #it will be a list, last element is last page number
#page no will be of string type
#print(pages) in the above steps we just used the base url(soup) and found the number of pages

#making final url of each page.
list=[]
base_url="https://www.flipkart.com/search?q=samsung+best+mobiles&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page="
for i in range(1,int(last_page)+1):
    final_url=base_url+str(i)
#opening each page    
    r=requests.get(final_url,headers={'User-agent':'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:61.0) Gecko/20100101 Firefox/61.0'}) #this is base base  (not page 1)
    c=r.content
    soup=BeautifulSoup(c,"html.parser")
    print(final_url)   #to learn this trick see .txt file present in the same folder

#scrapping .
    all_rows=soup.find_all("div",{"class":"_13oc-S"})  #fetching all rows 
    #print(len(all_rows))
    for item in all_rows:
        dict={}

        try:
            dict["Mobile Name"]=item.find("div",{"class":"_4rR01T"}).text   #fetching phone name
        except:
            dict["Mobile Name"]=None

        try:
            dict["Price"]=item.find("div",{"class":"_30jeq3 _1_WHN1"}).text  #fetching price
        except:
            dict["price"]=None

        try:
            dict["Ram | Rom"]=item.find_all("li",{"class":"rgWa7D"})[0].text  #fetcing ram ,rom  details  (see source code , li has many things in it)
        except:
            dict["Ram | Rom"]=None

        try:
            dict["Display"]=item.find_all("li",{"class":"rgWa7D"})[1].text  #fetching display details
        except:
            dict["Display"]=None

        try:
            dict["Camera"]=item.find_all("li",{"class":"rgWa7D"})[2].text  #fetching camera details
        except:
            dict["Camera"]=None

        try:
            dict["Battery"]=item.find_all("li",{"class":"rgWa7D"})[3].text  #fetching battery details
        except:
            dict["Battery"]=None

        try:
            dict["Processor"]=item.find_all("li",{"class":"rgWa7D"})[4].text  #fetching processor details
        except:
            dict["Processor"]=None

        try:
            dict["Rating"]=item.find_all("div",{"class":"_3LWZlK"})[0].text   #fetching rating, in list 1st elemment is rating,,(see source code)
        except:
            dict["Rating"]=None

        list.append(dict)
df=pandas.DataFrame(list)
#print(df)
df.to_csv("Final.csv")
    
